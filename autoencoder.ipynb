{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dim=28\n",
    "encoded_dim=10\n",
    "import torch.nn.functional as F\n",
    "class autoencoder(nn.Module):\n",
    "    def __init__(self,in_dim,encoded_dim):\n",
    "        super(autoencoder, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_dim, in_dim-2)\n",
    "        self.fc2 = nn.Linear(in_dim-2, in_dim-4)\n",
    "        self.fc3 = nn.Linear(in_dim-4, in_dim-6)\n",
    "        self.fc4 = nn.Linear(in_dim-6, encoded_dim)\n",
    "        self.fc5=nn.Linear(encoded_dim,encoded_dim+10)\n",
    "        self.fc6=nn.Linear(encoded_dim+10,in_dim)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x=self.fc4(x)\n",
    "        x=F.relu(self.fc5(x))\n",
    "        x=self.fc6(x)\n",
    "        return x\n",
    "net=autoencoder(in_dim,encoded_dim)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.0005, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=1,\n",
    "                                          shuffle=True, num_workers=1)\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=1,\n",
    "                                         shuffle=False, num_workers=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 0.556\n",
      "[1,  4000] loss: 0.315\n",
      "[1,  6000] loss: 0.295\n",
      "[1,  8000] loss: 0.267\n",
      "[1, 10000] loss: 0.248\n",
      "[1, 12000] loss: 0.226\n",
      "[1, 14000] loss: 0.215\n",
      "[1, 16000] loss: 0.203\n",
      "[1, 18000] loss: 0.195\n",
      "[1, 20000] loss: 0.184\n",
      "[1, 22000] loss: 0.169\n",
      "[1, 24000] loss: 0.165\n",
      "[1, 26000] loss: 0.160\n",
      "[1, 28000] loss: 0.159\n",
      "[1, 30000] loss: 0.157\n",
      "[1, 32000] loss: 0.156\n",
      "[1, 34000] loss: 0.156\n",
      "[1, 36000] loss: 0.155\n",
      "[1, 38000] loss: 0.156\n",
      "[1, 40000] loss: 0.153\n",
      "[1, 42000] loss: 0.150\n",
      "[1, 44000] loss: 0.145\n",
      "[1, 46000] loss: 0.127\n",
      "[1, 48000] loss: 0.112\n",
      "[1, 50000] loss: 0.105\n",
      "[1, 52000] loss: 0.103\n",
      "[1, 54000] loss: 0.098\n",
      "[1, 56000] loss: 0.096\n",
      "[1, 58000] loss: 0.092\n",
      "[1, 60000] loss: 0.090\n",
      "[2,  2000] loss: 0.086\n",
      "[2,  4000] loss: 0.084\n",
      "[2,  6000] loss: 0.086\n",
      "[2,  8000] loss: 0.084\n",
      "[2, 10000] loss: 0.083\n",
      "[2, 12000] loss: 0.083\n",
      "[2, 14000] loss: 0.082\n",
      "[2, 16000] loss: 0.082\n",
      "[2, 18000] loss: 0.081\n",
      "[2, 20000] loss: 0.081\n",
      "[2, 22000] loss: 0.080\n",
      "[2, 24000] loss: 0.081\n",
      "[2, 26000] loss: 0.081\n",
      "[2, 28000] loss: 0.080\n",
      "[2, 30000] loss: 0.079\n",
      "[2, 32000] loss: 0.079\n",
      "[2, 34000] loss: 0.078\n",
      "[2, 36000] loss: 0.079\n",
      "[2, 38000] loss: 0.077\n",
      "[2, 40000] loss: 0.077\n",
      "[2, 42000] loss: 0.076\n",
      "[2, 44000] loss: 0.076\n",
      "[2, 46000] loss: 0.075\n",
      "[2, 48000] loss: 0.075\n",
      "[2, 50000] loss: 0.073\n",
      "[2, 52000] loss: 0.073\n",
      "[2, 54000] loss: 0.071\n",
      "[2, 56000] loss: 0.071\n",
      "[2, 58000] loss: 0.068\n",
      "[2, 60000] loss: 0.068\n",
      "[3,  2000] loss: 0.066\n",
      "[3,  4000] loss: 0.066\n",
      "[3,  6000] loss: 0.065\n",
      "[3,  8000] loss: 0.063\n",
      "[3, 10000] loss: 0.062\n",
      "[3, 12000] loss: 0.061\n",
      "[3, 14000] loss: 0.060\n",
      "[3, 16000] loss: 0.058\n",
      "[3, 18000] loss: 0.058\n",
      "[3, 20000] loss: 0.057\n",
      "[3, 22000] loss: 0.056\n",
      "[3, 24000] loss: 0.056\n",
      "[3, 26000] loss: 0.056\n",
      "[3, 28000] loss: 0.055\n",
      "[3, 30000] loss: 0.054\n",
      "[3, 32000] loss: 0.054\n",
      "[3, 34000] loss: 0.053\n",
      "[3, 36000] loss: 0.052\n",
      "[3, 38000] loss: 0.052\n",
      "[3, 40000] loss: 0.052\n",
      "[3, 42000] loss: 0.051\n",
      "[3, 44000] loss: 0.050\n",
      "[3, 46000] loss: 0.050\n",
      "[3, 48000] loss: 0.051\n",
      "[3, 50000] loss: 0.049\n",
      "[3, 52000] loss: 0.049\n",
      "[3, 54000] loss: 0.048\n",
      "[3, 56000] loss: 0.048\n",
      "[3, 58000] loss: 0.048\n",
      "[3, 60000] loss: 0.048\n",
      "[4,  2000] loss: 0.047\n",
      "[4,  4000] loss: 0.046\n",
      "[4,  6000] loss: 0.046\n",
      "[4,  8000] loss: 0.046\n",
      "[4, 10000] loss: 0.045\n",
      "[4, 12000] loss: 0.044\n",
      "[4, 14000] loss: 0.044\n",
      "[4, 16000] loss: 0.043\n",
      "[4, 18000] loss: 0.043\n",
      "[4, 20000] loss: 0.043\n",
      "[4, 22000] loss: 0.043\n",
      "[4, 24000] loss: 0.041\n",
      "[4, 26000] loss: 0.041\n",
      "[4, 28000] loss: 0.040\n",
      "[4, 30000] loss: 0.040\n",
      "[4, 32000] loss: 0.040\n",
      "[4, 34000] loss: 0.039\n",
      "[4, 36000] loss: 0.039\n",
      "[4, 38000] loss: 0.038\n",
      "[4, 40000] loss: 0.039\n",
      "[4, 42000] loss: 0.037\n",
      "[4, 44000] loss: 0.036\n",
      "[4, 46000] loss: 0.037\n",
      "[4, 48000] loss: 0.036\n",
      "[4, 50000] loss: 0.037\n",
      "[4, 52000] loss: 0.036\n",
      "[4, 54000] loss: 0.035\n",
      "[4, 56000] loss: 0.035\n",
      "[4, 58000] loss: 0.035\n",
      "[4, 60000] loss: 0.035\n",
      "[5,  2000] loss: 0.034\n",
      "[5,  4000] loss: 0.034\n",
      "[5,  6000] loss: 0.034\n",
      "[5,  8000] loss: 0.033\n",
      "[5, 10000] loss: 0.033\n",
      "[5, 12000] loss: 0.032\n",
      "[5, 14000] loss: 0.032\n",
      "[5, 16000] loss: 0.032\n",
      "[5, 18000] loss: 0.032\n",
      "[5, 20000] loss: 0.031\n",
      "[5, 22000] loss: 0.032\n",
      "[5, 24000] loss: 0.031\n",
      "[5, 26000] loss: 0.031\n",
      "[5, 28000] loss: 0.030\n",
      "[5, 30000] loss: 0.030\n",
      "[5, 32000] loss: 0.031\n",
      "[5, 34000] loss: 0.030\n",
      "[5, 36000] loss: 0.029\n",
      "[5, 38000] loss: 0.029\n",
      "[5, 40000] loss: 0.030\n",
      "[5, 42000] loss: 0.029\n",
      "[5, 44000] loss: 0.030\n",
      "[5, 46000] loss: 0.029\n",
      "[5, 48000] loss: 0.029\n",
      "[5, 50000] loss: 0.029\n",
      "[5, 52000] loss: 0.028\n",
      "[5, 54000] loss: 0.028\n",
      "[5, 56000] loss: 0.029\n",
      "[5, 58000] loss: 0.028\n",
      "[5, 60000] loss: 0.029\n",
      "[6,  2000] loss: 0.027\n",
      "[6,  4000] loss: 0.028\n",
      "[6,  6000] loss: 0.028\n",
      "[6,  8000] loss: 0.028\n",
      "[6, 10000] loss: 0.028\n",
      "[6, 12000] loss: 0.029\n",
      "[6, 14000] loss: 0.028\n",
      "[6, 16000] loss: 0.027\n",
      "[6, 18000] loss: 0.028\n",
      "[6, 20000] loss: 0.027\n",
      "[6, 22000] loss: 0.027\n",
      "[6, 24000] loss: 0.027\n",
      "[6, 26000] loss: 0.027\n",
      "[6, 28000] loss: 0.027\n",
      "[6, 30000] loss: 0.027\n",
      "[6, 32000] loss: 0.027\n",
      "[6, 34000] loss: 0.026\n",
      "[6, 36000] loss: 0.026\n",
      "[6, 38000] loss: 0.027\n",
      "[6, 40000] loss: 0.026\n",
      "[6, 42000] loss: 0.027\n",
      "[6, 44000] loss: 0.026\n",
      "[6, 46000] loss: 0.026\n",
      "[6, 48000] loss: 0.026\n",
      "[6, 50000] loss: 0.026\n",
      "[6, 52000] loss: 0.026\n",
      "[6, 54000] loss: 0.026\n",
      "[6, 56000] loss: 0.026\n",
      "[6, 58000] loss: 0.026\n",
      "[6, 60000] loss: 0.026\n",
      "[7,  2000] loss: 0.026\n",
      "[7,  4000] loss: 0.026\n",
      "[7,  6000] loss: 0.025\n",
      "[7,  8000] loss: 0.026\n",
      "[7, 10000] loss: 0.026\n",
      "[7, 12000] loss: 0.025\n",
      "[7, 14000] loss: 0.025\n",
      "[7, 16000] loss: 0.025\n",
      "[7, 18000] loss: 0.025\n",
      "[7, 20000] loss: 0.025\n",
      "[7, 22000] loss: 0.025\n",
      "[7, 24000] loss: 0.025\n",
      "[7, 26000] loss: 0.025\n",
      "[7, 28000] loss: 0.024\n",
      "[7, 30000] loss: 0.025\n",
      "[7, 32000] loss: 0.025\n",
      "[7, 34000] loss: 0.024\n",
      "[7, 36000] loss: 0.025\n",
      "[7, 38000] loss: 0.025\n",
      "[7, 40000] loss: 0.025\n",
      "[7, 42000] loss: 0.024\n",
      "[7, 44000] loss: 0.024\n",
      "[7, 46000] loss: 0.024\n",
      "[7, 48000] loss: 0.024\n",
      "[7, 50000] loss: 0.024\n",
      "[7, 52000] loss: 0.024\n",
      "[7, 54000] loss: 0.024\n",
      "[7, 56000] loss: 0.024\n",
      "[7, 58000] loss: 0.023\n",
      "[7, 60000] loss: 0.023\n",
      "[8,  2000] loss: 0.023\n",
      "[8,  4000] loss: 0.023\n",
      "[8,  6000] loss: 0.023\n",
      "[8,  8000] loss: 0.024\n",
      "[8, 10000] loss: 0.024\n",
      "[8, 12000] loss: 0.023\n",
      "[8, 14000] loss: 0.023\n",
      "[8, 16000] loss: 0.023\n",
      "[8, 18000] loss: 0.023\n",
      "[8, 20000] loss: 0.022\n",
      "[8, 22000] loss: 0.023\n",
      "[8, 24000] loss: 0.023\n",
      "[8, 26000] loss: 0.023\n",
      "[8, 28000] loss: 0.022\n",
      "[8, 30000] loss: 0.022\n",
      "[8, 32000] loss: 0.022\n",
      "[8, 34000] loss: 0.023\n",
      "[8, 36000] loss: 0.022\n",
      "[8, 38000] loss: 0.022\n",
      "[8, 40000] loss: 0.022\n",
      "[8, 42000] loss: 0.022\n",
      "[8, 44000] loss: 0.022\n",
      "[8, 46000] loss: 0.022\n",
      "[8, 48000] loss: 0.022\n",
      "[8, 50000] loss: 0.022\n",
      "[8, 52000] loss: 0.022\n",
      "[8, 54000] loss: 0.022\n",
      "[8, 56000] loss: 0.022\n",
      "[8, 58000] loss: 0.022\n",
      "[8, 60000] loss: 0.022\n",
      "[9,  2000] loss: 0.021\n",
      "[9,  4000] loss: 0.022\n",
      "[9,  6000] loss: 0.022\n",
      "[9,  8000] loss: 0.021\n",
      "[9, 10000] loss: 0.022\n",
      "[9, 12000] loss: 0.021\n",
      "[9, 14000] loss: 0.021\n",
      "[9, 16000] loss: 0.021\n",
      "[9, 18000] loss: 0.022\n",
      "[9, 20000] loss: 0.021\n",
      "[9, 22000] loss: 0.022\n",
      "[9, 24000] loss: 0.021\n",
      "[9, 26000] loss: 0.021\n",
      "[9, 28000] loss: 0.022\n",
      "[9, 30000] loss: 0.021\n",
      "[9, 32000] loss: 0.021\n",
      "[9, 34000] loss: 0.021\n",
      "[9, 36000] loss: 0.021\n",
      "[9, 38000] loss: 0.021\n",
      "[9, 40000] loss: 0.022\n",
      "[9, 42000] loss: 0.021\n",
      "[9, 44000] loss: 0.021\n",
      "[9, 46000] loss: 0.021\n",
      "[9, 48000] loss: 0.021\n",
      "[9, 50000] loss: 0.021\n",
      "[9, 52000] loss: 0.021\n",
      "[9, 54000] loss: 0.021\n",
      "[9, 56000] loss: 0.021\n",
      "[9, 58000] loss: 0.021\n",
      "[9, 60000] loss: 0.021\n",
      "[10,  2000] loss: 0.021\n",
      "[10,  4000] loss: 0.021\n",
      "[10,  6000] loss: 0.021\n",
      "[10,  8000] loss: 0.021\n",
      "[10, 10000] loss: 0.021\n",
      "[10, 12000] loss: 0.021\n",
      "[10, 14000] loss: 0.021\n",
      "[10, 16000] loss: 0.021\n",
      "[10, 18000] loss: 0.021\n",
      "[10, 20000] loss: 0.021\n",
      "[10, 22000] loss: 0.020\n",
      "[10, 24000] loss: 0.021\n",
      "[10, 26000] loss: 0.020\n",
      "[10, 28000] loss: 0.020\n",
      "[10, 30000] loss: 0.021\n",
      "[10, 32000] loss: 0.021\n",
      "[10, 34000] loss: 0.021\n",
      "[10, 36000] loss: 0.021\n",
      "[10, 38000] loss: 0.020\n",
      "[10, 40000] loss: 0.021\n",
      "[10, 42000] loss: 0.021\n",
      "[10, 44000] loss: 0.020\n",
      "[10, 46000] loss: 0.020\n",
      "[10, 48000] loss: 0.020\n",
      "[10, 50000] loss: 0.020\n",
      "[10, 52000] loss: 0.020\n",
      "[10, 54000] loss: 0.020\n",
      "[10, 56000] loss: 0.020\n",
      "[10, 58000] loss: 0.020\n",
      "[10, 60000] loss: 0.020\n",
      "[11,  2000] loss: 0.020\n",
      "[11,  4000] loss: 0.020\n",
      "[11,  6000] loss: 0.020\n",
      "[11,  8000] loss: 0.020\n",
      "[11, 10000] loss: 0.021\n",
      "[11, 12000] loss: 0.021\n",
      "[11, 14000] loss: 0.021\n",
      "[11, 16000] loss: 0.020\n",
      "[11, 18000] loss: 0.020\n",
      "[11, 20000] loss: 0.020\n",
      "[11, 22000] loss: 0.020\n",
      "[11, 24000] loss: 0.020\n",
      "[11, 26000] loss: 0.020\n",
      "[11, 28000] loss: 0.020\n",
      "[11, 30000] loss: 0.020\n",
      "[11, 32000] loss: 0.020\n",
      "[11, 34000] loss: 0.020\n",
      "[11, 36000] loss: 0.020\n",
      "[11, 38000] loss: 0.020\n",
      "[11, 40000] loss: 0.020\n",
      "[11, 42000] loss: 0.020\n",
      "[11, 44000] loss: 0.020\n",
      "[11, 46000] loss: 0.020\n",
      "[11, 48000] loss: 0.020\n",
      "[11, 50000] loss: 0.020\n",
      "[11, 52000] loss: 0.020\n",
      "[11, 54000] loss: 0.020\n",
      "[11, 56000] loss: 0.020\n",
      "[11, 58000] loss: 0.020\n",
      "[11, 60000] loss: 0.020\n",
      "[12,  2000] loss: 0.020\n",
      "[12,  4000] loss: 0.020\n",
      "[12,  6000] loss: 0.020\n",
      "[12,  8000] loss: 0.020\n",
      "[12, 10000] loss: 0.020\n",
      "[12, 12000] loss: 0.020\n",
      "[12, 14000] loss: 0.020\n",
      "[12, 16000] loss: 0.020\n",
      "[12, 18000] loss: 0.020\n",
      "[12, 20000] loss: 0.020\n",
      "[12, 22000] loss: 0.020\n",
      "[12, 24000] loss: 0.020\n",
      "[12, 26000] loss: 0.020\n",
      "[12, 28000] loss: 0.020\n",
      "[12, 30000] loss: 0.020\n",
      "[12, 32000] loss: 0.020\n",
      "[12, 34000] loss: 0.020\n",
      "[12, 36000] loss: 0.020\n",
      "[12, 38000] loss: 0.020\n",
      "[12, 40000] loss: 0.020\n",
      "[12, 42000] loss: 0.020\n",
      "[12, 44000] loss: 0.020\n",
      "[12, 46000] loss: 0.020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12, 48000] loss: 0.020\n",
      "[12, 50000] loss: 0.019\n",
      "[12, 52000] loss: 0.020\n",
      "[12, 54000] loss: 0.020\n",
      "[12, 56000] loss: 0.020\n",
      "[12, 58000] loss: 0.019\n",
      "[12, 60000] loss: 0.019\n",
      "[13,  2000] loss: 0.020\n",
      "[13,  4000] loss: 0.019\n",
      "[13,  6000] loss: 0.019\n",
      "[13,  8000] loss: 0.019\n",
      "[13, 10000] loss: 0.020\n",
      "[13, 12000] loss: 0.019\n",
      "[13, 14000] loss: 0.019\n",
      "[13, 16000] loss: 0.019\n",
      "[13, 18000] loss: 0.019\n",
      "[13, 20000] loss: 0.019\n",
      "[13, 22000] loss: 0.020\n",
      "[13, 24000] loss: 0.019\n",
      "[13, 26000] loss: 0.019\n",
      "[13, 28000] loss: 0.019\n",
      "[13, 30000] loss: 0.020\n",
      "[13, 32000] loss: 0.019\n",
      "[13, 34000] loss: 0.020\n",
      "[13, 36000] loss: 0.019\n",
      "[13, 38000] loss: 0.019\n",
      "[13, 40000] loss: 0.019\n",
      "[13, 42000] loss: 0.019\n",
      "[13, 44000] loss: 0.019\n",
      "[13, 46000] loss: 0.020\n",
      "[13, 48000] loss: 0.019\n",
      "[13, 50000] loss: 0.019\n",
      "[13, 52000] loss: 0.019\n",
      "[13, 54000] loss: 0.019\n",
      "[13, 56000] loss: 0.019\n",
      "[13, 58000] loss: 0.019\n",
      "[13, 60000] loss: 0.019\n",
      "[14,  2000] loss: 0.019\n",
      "[14,  4000] loss: 0.019\n",
      "[14,  6000] loss: 0.018\n",
      "[14,  8000] loss: 0.018\n",
      "[14, 10000] loss: 0.019\n",
      "[14, 12000] loss: 0.018\n",
      "[14, 14000] loss: 0.019\n",
      "[14, 16000] loss: 0.018\n",
      "[14, 18000] loss: 0.019\n",
      "[14, 20000] loss: 0.018\n",
      "[14, 22000] loss: 0.018\n",
      "[14, 24000] loss: 0.018\n",
      "[14, 26000] loss: 0.018\n",
      "[14, 28000] loss: 0.018\n",
      "[14, 30000] loss: 0.018\n",
      "[14, 32000] loss: 0.018\n",
      "[14, 34000] loss: 0.018\n",
      "[14, 36000] loss: 0.018\n",
      "[14, 38000] loss: 0.018\n",
      "[14, 40000] loss: 0.018\n",
      "[14, 42000] loss: 0.018\n",
      "[14, 44000] loss: 0.018\n",
      "[14, 46000] loss: 0.018\n",
      "[14, 48000] loss: 0.017\n",
      "[14, 50000] loss: 0.017\n",
      "[14, 52000] loss: 0.018\n",
      "[14, 54000] loss: 0.018\n",
      "[14, 56000] loss: 0.017\n",
      "[14, 58000] loss: 0.018\n",
      "[14, 60000] loss: 0.017\n",
      "[15,  2000] loss: 0.017\n",
      "[15,  4000] loss: 0.017\n",
      "[15,  6000] loss: 0.018\n",
      "[15,  8000] loss: 0.017\n",
      "[15, 10000] loss: 0.017\n",
      "[15, 12000] loss: 0.017\n",
      "[15, 14000] loss: 0.017\n",
      "[15, 16000] loss: 0.017\n",
      "[15, 18000] loss: 0.017\n",
      "[15, 20000] loss: 0.017\n",
      "[15, 22000] loss: 0.017\n",
      "[15, 24000] loss: 0.017\n",
      "[15, 26000] loss: 0.017\n",
      "[15, 28000] loss: 0.017\n",
      "[15, 30000] loss: 0.017\n",
      "[15, 32000] loss: 0.017\n",
      "[15, 34000] loss: 0.017\n",
      "[15, 36000] loss: 0.017\n",
      "[15, 38000] loss: 0.017\n",
      "[15, 40000] loss: 0.017\n",
      "[15, 42000] loss: 0.017\n",
      "[15, 44000] loss: 0.016\n",
      "[15, 46000] loss: 0.017\n",
      "[15, 48000] loss: 0.017\n",
      "[15, 50000] loss: 0.017\n",
      "[15, 52000] loss: 0.017\n",
      "[15, 54000] loss: 0.016\n",
      "[15, 56000] loss: 0.017\n",
      "[15, 58000] loss: 0.017\n",
      "[15, 60000] loss: 0.016\n",
      "[16,  2000] loss: 0.016\n",
      "[16,  4000] loss: 0.016\n",
      "[16,  6000] loss: 0.017\n",
      "[16,  8000] loss: 0.016\n",
      "[16, 10000] loss: 0.016\n",
      "[16, 12000] loss: 0.017\n",
      "[16, 14000] loss: 0.016\n",
      "[16, 16000] loss: 0.016\n",
      "[16, 18000] loss: 0.016\n",
      "[16, 20000] loss: 0.016\n",
      "[16, 22000] loss: 0.016\n",
      "[16, 24000] loss: 0.016\n",
      "[16, 26000] loss: 0.016\n",
      "[16, 28000] loss: 0.016\n",
      "[16, 30000] loss: 0.017\n",
      "[16, 32000] loss: 0.016\n",
      "[16, 34000] loss: 0.016\n",
      "[16, 36000] loss: 0.016\n",
      "[16, 38000] loss: 0.016\n",
      "[16, 40000] loss: 0.016\n",
      "[16, 42000] loss: 0.016\n",
      "[16, 44000] loss: 0.016\n",
      "[16, 46000] loss: 0.016\n",
      "[16, 48000] loss: 0.016\n",
      "[16, 50000] loss: 0.017\n",
      "[16, 52000] loss: 0.016\n",
      "[16, 54000] loss: 0.016\n",
      "[16, 56000] loss: 0.016\n",
      "[16, 58000] loss: 0.016\n",
      "[16, 60000] loss: 0.016\n",
      "[17,  2000] loss: 0.016\n",
      "[17,  4000] loss: 0.016\n",
      "[17,  6000] loss: 0.016\n",
      "[17,  8000] loss: 0.015\n",
      "[17, 10000] loss: 0.016\n",
      "[17, 12000] loss: 0.016\n",
      "[17, 14000] loss: 0.016\n",
      "[17, 16000] loss: 0.016\n",
      "[17, 18000] loss: 0.016\n",
      "[17, 20000] loss: 0.016\n",
      "[17, 22000] loss: 0.016\n",
      "[17, 24000] loss: 0.016\n",
      "[17, 26000] loss: 0.016\n",
      "[17, 28000] loss: 0.016\n",
      "[17, 30000] loss: 0.016\n",
      "[17, 32000] loss: 0.016\n",
      "[17, 34000] loss: 0.016\n",
      "[17, 36000] loss: 0.016\n",
      "[17, 38000] loss: 0.016\n",
      "[17, 40000] loss: 0.016\n",
      "[17, 42000] loss: 0.016\n",
      "[17, 44000] loss: 0.015\n",
      "[17, 46000] loss: 0.016\n",
      "[17, 48000] loss: 0.016\n",
      "[17, 50000] loss: 0.015\n",
      "[17, 52000] loss: 0.016\n",
      "[17, 54000] loss: 0.016\n",
      "[17, 56000] loss: 0.016\n",
      "[17, 58000] loss: 0.016\n",
      "[17, 60000] loss: 0.016\n",
      "[18,  2000] loss: 0.015\n",
      "[18,  4000] loss: 0.015\n",
      "[18,  6000] loss: 0.016\n",
      "[18,  8000] loss: 0.016\n",
      "[18, 10000] loss: 0.016\n",
      "[18, 12000] loss: 0.015\n",
      "[18, 14000] loss: 0.016\n",
      "[18, 16000] loss: 0.016\n",
      "[18, 18000] loss: 0.015\n",
      "[18, 20000] loss: 0.016\n",
      "[18, 22000] loss: 0.016\n",
      "[18, 24000] loss: 0.015\n",
      "[18, 26000] loss: 0.015\n",
      "[18, 28000] loss: 0.015\n",
      "[18, 30000] loss: 0.015\n",
      "[18, 32000] loss: 0.016\n",
      "[18, 34000] loss: 0.015\n",
      "[18, 36000] loss: 0.015\n",
      "[18, 38000] loss: 0.015\n",
      "[18, 40000] loss: 0.015\n",
      "[18, 42000] loss: 0.015\n",
      "[18, 44000] loss: 0.015\n",
      "[18, 46000] loss: 0.015\n",
      "[18, 48000] loss: 0.016\n",
      "[18, 50000] loss: 0.016\n",
      "[18, 52000] loss: 0.015\n",
      "[18, 54000] loss: 0.016\n",
      "[18, 56000] loss: 0.016\n",
      "[18, 58000] loss: 0.015\n",
      "[18, 60000] loss: 0.016\n",
      "[19,  2000] loss: 0.015\n",
      "[19,  4000] loss: 0.015\n",
      "[19,  6000] loss: 0.015\n",
      "[19,  8000] loss: 0.015\n",
      "[19, 10000] loss: 0.015\n",
      "[19, 12000] loss: 0.015\n",
      "[19, 14000] loss: 0.015\n",
      "[19, 16000] loss: 0.015\n",
      "[19, 18000] loss: 0.015\n",
      "[19, 20000] loss: 0.016\n",
      "[19, 22000] loss: 0.015\n",
      "[19, 24000] loss: 0.015\n",
      "[19, 26000] loss: 0.015\n",
      "[19, 28000] loss: 0.016\n",
      "[19, 30000] loss: 0.015\n",
      "[19, 32000] loss: 0.015\n",
      "[19, 34000] loss: 0.015\n",
      "[19, 36000] loss: 0.016\n",
      "[19, 38000] loss: 0.015\n",
      "[19, 40000] loss: 0.015\n",
      "[19, 42000] loss: 0.015\n",
      "[19, 44000] loss: 0.015\n",
      "[19, 46000] loss: 0.015\n",
      "[19, 48000] loss: 0.015\n",
      "[19, 50000] loss: 0.015\n",
      "[19, 52000] loss: 0.015\n",
      "[19, 54000] loss: 0.015\n",
      "[19, 56000] loss: 0.015\n",
      "[19, 58000] loss: 0.015\n",
      "[19, 60000] loss: 0.015\n",
      "[20,  2000] loss: 0.015\n",
      "[20,  4000] loss: 0.015\n",
      "[20,  6000] loss: 0.015\n",
      "[20,  8000] loss: 0.015\n",
      "[20, 10000] loss: 0.015\n",
      "[20, 12000] loss: 0.015\n",
      "[20, 14000] loss: 0.015\n",
      "[20, 16000] loss: 0.015\n",
      "[20, 18000] loss: 0.015\n",
      "[20, 20000] loss: 0.015\n",
      "[20, 22000] loss: 0.015\n",
      "[20, 24000] loss: 0.015\n",
      "[20, 26000] loss: 0.015\n",
      "[20, 28000] loss: 0.015\n",
      "[20, 30000] loss: 0.015\n",
      "[20, 32000] loss: 0.015\n",
      "[20, 34000] loss: 0.015\n",
      "[20, 36000] loss: 0.015\n",
      "[20, 38000] loss: 0.015\n",
      "[20, 40000] loss: 0.015\n",
      "[20, 42000] loss: 0.015\n",
      "[20, 44000] loss: 0.015\n",
      "[20, 46000] loss: 0.015\n",
      "[20, 48000] loss: 0.015\n",
      "[20, 50000] loss: 0.015\n",
      "[20, 52000] loss: 0.015\n",
      "[20, 54000] loss: 0.015\n",
      "[20, 56000] loss: 0.015\n",
      "[20, 58000] loss: 0.015\n",
      "[20, 60000] loss: 0.015\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(20):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        \n",
    "        x,y=data\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        xprime = net(x)\n",
    "        loss = criterion(xprime, x)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.0643, grad_fn=<SumBackward0>)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvqOYd8AAADPJJREFUeJzt3W+IXfWdx/HPx2yKYAo6Ww2DjZtuCQtRMNEhiBvX6K41q4VYDFIfLFkoiQ8a2ULRFffB5mFd+of6wMKUhsa1ayuk1QjiNg2KVjQkEf8k0UQnpGZi/pUEmojSjX73wZy0U537u9f775zx+37BMPee7z3nfLnMZ84595xzf44IAcjnvLobAFAPwg8kRfiBpAg/kBThB5Ii/EBShB9IivADSRF+IKm/GubKbHM5ITBgEeFOXtfTlt/2Stv7bL9t+75elgVguNzttf2250jaL+kmSZOSdki6MyL2FuZhyw8M2DC2/MskvR0RByLij5J+LmlVD8sDMES9hP9SSYemPZ+spv0F2+ts77S9s4d1AeizgX/gFxHjksYldvuBJully39Y0oJpz79YTQMwC/QS/h2SFtn+ku3PSfq6pC39aQvAoHW92x8RZ22vl/S/kuZI2hgRe/rWGYCB6vpUX1cr45gfGLihXOQDYPYi/EBShB9IivADSRF+ICnCDyRF+IGkCD+QFOEHkiL8QFKEH0iK8ANJEX4gKcIPJEX4gaQIP5AU4QeSIvxAUoQfSIrwA0kRfiApwg8kRfiBpAg/kBThB5Ii/EBShB9IivADSRF+IKmuh+iWJNsHJZ2W9KGksxEx1o+mAAxeT+Gv3BARv+/DcgAMEbv9QFK9hj8k/dr2Ltvr+tEQgOHodbd/eUQctn2JpK2234yI56a/oPqnwD8GoGEcEf1ZkL1B0pmI+G7hNf1ZGYCWIsKdvK7r3X7bF9j+/LnHkr4iaXe3ywMwXL3s9s+X9Cvb55bzPxHxdF+6AjBwfdvt72hl7PYDAzfw3X4AsxvhB5Ii/EBShB9IivADSRF+IKl+3NWXwurVq1vW1q5dW5z33XffLdY/+OCDYv2RRx4p1o8ePdqyNjExUZwXebHlB5Ii/EBShB9IivADSRF+ICnCDyRF+IGkuKW3QwcOHGhZW7hw4fAamcHp06db1vbs2TPETpplcnKyZe2BBx4ozrtr165+tzM03NILoIjwA0kRfiApwg8kRfiBpAg/kBThB5Lifv4Ole7Zv/LKK4vz7t27t1hfvHhxsb506dJifcWKFS1r11xzTXHeQ4cOFesLFiwo1ntx9uzZYv3EiRPF+ujoaNfrfuedd4r12Xyev1Ns+YGkCD+QFOEHkiL8QFKEH0iK8ANJEX4gqbb389veKOmrko5HxBXVtBFJv5C0UNJBSXdExKm2K5vF9/M32YUXXtiydtVVVxXn3bFjR7G+bNmyrnrqxPvvv1+s79+/v1h/8803i/WRkZGWtfXr1xfnfeihh4r1Juvn/fw/lbTyY9Puk7QtIhZJ2lY9BzCLtA1/RDwn6eTHJq+StKl6vEnSbX3uC8CAdXvMPz8ijlSPj0qa36d+AAxJz9f2R0SUjuVtr5O0rtf1AOivbrf8x2yPSlL1+3irF0bEeESMRcRYl+sCMADdhn+LpDXV4zWSnuhPOwCGpW34bT8q6UVJf2d70vY3JH1H0k2235L0T9VzALMI39uPxrr99tuL9ccee6xY3717d8ta6TsQJOnUqbaXrTQW39sPoIjwA0kRfiApwg8kRfiBpAg/kBSn+lCbiy++uFgvnaqTpEsuuaRYX716dcva5s2bi/POZpzqA1BE+IGkCD+QFOEHkiL8QFKEH0iK8ANJMUQ3atPu67PbXQfQ7rbbdl/tnR1bfiApwg8kRfiBpAg/kBThB5Ii/EBShB9Iivv5MVDXXntty9ozzzxTnHfu3LnF+vXXX1+sP//888X6ZxX38wMoIvxAUoQfSIrwA0kRfiApwg8kRfiBpNrez297o6SvSjoeEVdU0zZIWivpRPWy+yPiqUE1idnr1ltvbVlrdx5/27ZtxfqLL77YVU+Y0smW/6eSVs4w/QcRsaT6IfjALNM2/BHxnKSTQ+gFwBD1csy/3vZrtjfavqhvHQEYim7D/yNJX5a0RNIRSd9r9ULb62zvtL2zy3UBGICuwh8RxyLiw4j4SNKPJS0rvHY8IsYiYqzbJgH0X1fhtz067enXJJWHUwXQOJ2c6ntU0gpJX7A9Kek/Ja2wvURSSDoo6a4B9ghgALifHz05//zzi/UXXnihZe3yyy8vznvDDTcU65znnxn38wMoIvxAUoQfSIrwA0kRfiApwg8kxRDd6Mm9995brC9durRl7emnny7Oy6m8wWLLDyRF+IGkCD+QFOEHkiL8QFKEH0iK8ANJcUsvikpfvS1Jjz/+eLH+3nvvtaytXDnTl0L/2UsvvVSsY2bc0gugiPADSRF+ICnCDyRF+IGkCD+QFOEHkuJ+/uRGRkaK9QcffLBYnzNnTrH+1FOtB3DmPH692PIDSRF+ICnCDyRF+IGkCD+QFOEHkiL8QFJt7+e3vUDSw5LmSwpJ4xHxQ9sjkn4haaGkg5LuiIhTbZbF/fxDdt555f/v27dvL9avvvrqYn1iYqJYv/nmm1vWDhw4UJwX3enn/fxnJX07IhZLukbSN20vlnSfpG0RsUjStuo5gFmibfgj4khEvFw9Pi3pDUmXSlolaVP1sk2SbhtUkwD671Md89teKGmppO2S5kfEkap0VFOHBQBmiY6v7bc9T9JmSd+KiD/Yfz6siIhodTxve52kdb02CqC/Otry256rqeD/LCJ+WU0+Znu0qo9KOj7TvBExHhFjETHWj4YB9Efb8HtqE/8TSW9ExPenlbZIWlM9XiPpif63B2BQOjnVt1zS85Jel/RRNfl+TR33PybpMkm/09SpvpNtlsWpviFbtGhRsb5v376elr9q1api/cknn+xp+fj0Oj3V1/aYPyJ+K6nVwv7x0zQFoDm4wg9IivADSRF+ICnCDyRF+IGkCD+QFF/d/Rlw2WWXtaxt3bq1p2Xfc889xTrn8WcvtvxAUoQfSIrwA0kRfiApwg8kRfiBpAg/kBTn+T8D7rrrrpa10jUAnXj22Wd7mh/NxZYfSIrwA0kRfiApwg8kRfiBpAg/kBThB5LiPP8ssHz58mL97rvvHlIn+Cxhyw8kRfiBpAg/kBThB5Ii/EBShB9IivADSbU9z297gaSHJc2XFJLGI+KHtjdIWivpRPXS+yPiqUE1mtl1111XrM+bN6/rZU9MTBTrZ86c6XrZaLZOLvI5K+nbEfGy7c9L2mX73EgQP4iI7w6uPQCD0jb8EXFE0pHq8Wnbb0i6dNCNARisT3XMb3uhpKWStleT1tt+zfZG2xe1mGed7Z22d/bUKYC+6jj8tudJ2izpWxHxB0k/kvRlSUs0tWfwvZnmi4jxiBiLiLE+9AugTzoKv+25mgr+zyLil5IUEcci4sOI+EjSjyUtG1ybAPqtbfhtW9JPJL0REd+fNn102su+Jml3/9sDMCidfNr/95L+RdLrtl+ppt0v6U7bSzR1+u+gpNbfH43avPrqq8X6jTfeWKyfOnWqn+2gQTr5tP+3kjxDiXP6wCzGFX5AUoQfSIrwA0kRfiApwg8kRfiBpBwRw1uZPbyVAUlFxEyn5j+BLT+QFOEHkiL8QFKEH0iK8ANJEX4gKcIPJDXsIbp/L+l3055/oZrWRE3tral9SfTWrX729jedvnCoF/l8YuX2zqZ+t19Te2tqXxK9dauu3tjtB5Ii/EBSdYd/vOb1lzS1t6b2JdFbt2rprdZjfgD1qXvLD6AmtYTf9krb+2y/bfu+OnpoxfZB26/bfqXuIcaqYdCO2949bdqI7a2236p+zzhMWk29bbB9uHrvXrF9S029LbD9jO29tvfY/rdqeq3vXaGvWt63oe/2254jab+kmyRNStoh6c6I2DvURlqwfVDSWETUfk7Y9j9IOiPp4Yi4opr2X5JORsR3qn+cF0XEvzektw2SztQ9cnM1oMzo9JGlJd0m6V9V43tX6OsO1fC+1bHlXybp7Yg4EBF/lPRzSatq6KPxIuI5SSc/NnmVpE3V402a+uMZuha9NUJEHImIl6vHpyWdG1m61veu0Fct6gj/pZIOTXs+qWYN+R2Sfm17l+11dTczg/nVsOmSdFTS/DqbmUHbkZuH6WMjSzfmvetmxOt+4wO/T1oeEVdJ+mdJ36x2bxsppo7ZmnS6pqORm4dlhpGl/6TO967bEa/7rY7wH5a0YNrzL1bTGiEiDle/j0v6lZo3+vCxc4OkVr+P19zPnzRp5OaZRpZWA967Jo14XUf4d0haZPtLtj8n6euSttTQxyfYvqD6IEa2L5D0FTVv9OEtktZUj9dIeqLGXv5CU0ZubjWytGp+7xo34nVEDP1H0i2a+sR/QtJ/1NFDi77+VtKr1c+eunuT9KimdgP/T1OfjXxD0l9L2ibpLUm/kTTSoN7+W9Lrkl7TVNBGa+ptuaZ26V+T9Er1c0vd712hr1reN67wA5LiAz8gKcIPJEX4gaQIP5AU4QeSIvxAUoQfSIrwA0n9Pw9aPLAkcU5xAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(testloader)\n",
    "image, label = dataiter.next()\n",
    "print(criterion(image,net(image)))\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(image))\n",
    "#imshow(torchvision.utils.make_grid(net(image).detach()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Downloading https://files.pythonhosted.org/packages/f0/de/49aea99b9d088ce4457b5b171c016173347eba7b79753cdacbbd7da89dee/matplotlib-3.0.0-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (14.1MB)\n",
      "\u001b[K    100% |████████████████████████████████| 14.1MB 34kB/s eta 0:00:011   18% |██████                          | 2.7MB 5.2MB/s eta 0:00:03\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.10.0 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from matplotlib)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from matplotlib)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading https://files.pythonhosted.org/packages/f7/d2/e07d3ebb2bd7af696440ce7e754c59dd546ffe1bbe732c8ab68b9c834e61/cycler-0.10.0-py2.py3-none-any.whl\n",
      "Collecting pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 (from matplotlib)\n",
      "  Downloading https://files.pythonhosted.org/packages/2b/4a/f06b45ab9690d4c37641ec776f7ad691974f4cf6943a73267475b05cbfca/pyparsing-2.2.2-py2.py3-none-any.whl (57kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 1.4MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting kiwisolver>=1.0.1 (from matplotlib)\n",
      "  Downloading https://files.pythonhosted.org/packages/fb/96/619db9bf08f652790fa9f3c3884a67dc43da4bdaa185a5aa2117eb4651e1/kiwisolver-1.0.1-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (108kB)\n",
      "\u001b[K    100% |████████████████████████████████| 112kB 2.0MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from python-dateutil>=2.1->matplotlib)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from kiwisolver>=1.0.1->matplotlib)\n",
      "Installing collected packages: cycler, pyparsing, kiwisolver, matplotlib\n",
      "Successfully installed cycler-0.10.0 kiwisolver-1.0.1 matplotlib-3.0.0 pyparsing-2.2.2\n",
      "\u001b[33mYou are using pip version 9.0.3, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
