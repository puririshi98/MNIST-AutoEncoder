{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dim=784\n",
    "encoded_dim=30\n",
    "import torch.nn.functional as F\n",
    "\n",
    "X=[]\n",
    "Y=[]\n",
    "def saveencoded(self, input, output):\n",
    "    global X\n",
    "    X+=output.detach().numpy().tolist()\n",
    "class autoencoder(nn.Module):\n",
    "    def __init__(self,in_dim,encoded_dim):\n",
    "        super(autoencoder, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_dim, in_dim-300)\n",
    "        \n",
    "        self.fc4 = nn.Linear(in_dim-500, encoded_dim)\n",
    "        self.fc5=nn.Linear(encoded_dim,encoded_dim+250)\n",
    "        self.fc6=nn.Linear(encoded_dim+250,in_dim)\n",
    "    def forward(self, x):\n",
    "        x=x.reshape(-1,784)\n",
    "        x = F.relu(self.fc1(x))\n",
    "#         x=F.relu(self.fc3(x))\n",
    "        x=self.fc4(x)\n",
    "        x=F.relu(self.fc5(x))\n",
    "        x=self.fc6(x)\n",
    "        x=x.reshape(-1,1,28,28)\n",
    "        return x\n",
    "net=autoencoder(in_dim,encoded_dim)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.00001, momentum=.9)\n",
    "scheduler=torch.optim.lr_scheduler.StepLR(optimizer, 1, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=1,\n",
    "                                          shuffle=True, num_workers=1)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=1,\n",
    "                                         shuffle=False, num_workers=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 0.025\n",
      "[1,  4000] loss: 0.025\n",
      "[1,  6000] loss: 0.025\n",
      "[1,  8000] loss: 0.025\n",
      "[1, 10000] loss: 0.025\n",
      "[1, 12000] loss: 0.025\n",
      "[1, 14000] loss: 0.025\n",
      "[1, 16000] loss: 0.025\n",
      "[1, 18000] loss: 0.025\n",
      "[1, 20000] loss: 0.025\n",
      "[1, 22000] loss: 0.025\n",
      "[1, 24000] loss: 0.025\n",
      "[1, 26000] loss: 0.025\n",
      "[1, 28000] loss: 0.025\n",
      "[1, 30000] loss: 0.025\n",
      "[1, 32000] loss: 0.025\n",
      "[1, 34000] loss: 0.025\n",
      "[1, 36000] loss: 0.025\n",
      "[1, 38000] loss: 0.025\n",
      "[1, 40000] loss: 0.025\n",
      "[1, 42000] loss: 0.025\n",
      "[1, 44000] loss: 0.025\n",
      "[1, 46000] loss: 0.025\n",
      "[1, 48000] loss: 0.025\n",
      "[1, 50000] loss: 0.025\n",
      "[1, 52000] loss: 0.025\n",
      "[1, 54000] loss: 0.025\n",
      "[1, 56000] loss: 0.025\n",
      "[1, 58000] loss: 0.025\n",
      "[1, 60000] loss: 0.025\n",
      "[2,  2000] loss: 0.025\n",
      "[2,  4000] loss: 0.025\n",
      "[2,  6000] loss: 0.025\n",
      "[2,  8000] loss: 0.025\n",
      "[2, 10000] loss: 0.025\n",
      "[2, 12000] loss: 0.025\n",
      "[2, 14000] loss: 0.025\n",
      "[2, 16000] loss: 0.025\n",
      "[2, 18000] loss: 0.025\n",
      "[2, 20000] loss: 0.025\n",
      "[2, 22000] loss: 0.025\n",
      "[2, 24000] loss: 0.025\n",
      "[2, 26000] loss: 0.025\n",
      "[2, 28000] loss: 0.025\n",
      "[2, 30000] loss: 0.025\n",
      "[2, 32000] loss: 0.025\n",
      "[2, 34000] loss: 0.025\n",
      "[2, 36000] loss: 0.025\n",
      "[2, 38000] loss: 0.025\n",
      "[2, 40000] loss: 0.025\n",
      "[2, 42000] loss: 0.025\n",
      "[2, 44000] loss: 0.025\n",
      "[2, 46000] loss: 0.025\n",
      "[2, 48000] loss: 0.025\n",
      "[2, 50000] loss: 0.025\n",
      "[2, 52000] loss: 0.025\n",
      "[2, 54000] loss: 0.025\n",
      "[2, 56000] loss: 0.025\n",
      "[2, 58000] loss: 0.025\n",
      "[2, 60000] loss: 0.025\n",
      "[3,  2000] loss: 0.025\n",
      "[3,  4000] loss: 0.025\n",
      "[3,  6000] loss: 0.025\n",
      "[3,  8000] loss: 0.025\n",
      "[3, 10000] loss: 0.025\n",
      "[3, 12000] loss: 0.025\n",
      "[3, 14000] loss: 0.025\n",
      "[3, 16000] loss: 0.025\n",
      "[3, 18000] loss: 0.025\n",
      "[3, 20000] loss: 0.025\n",
      "[3, 22000] loss: 0.025\n",
      "[3, 24000] loss: 0.025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-68:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 187, in default_collate\n",
      "    return [default_collate(samples) for samples in transposed]\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 187, in <listcomp>\n",
      "    return [default_collate(samples) for samples in transposed]\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 162, in default_collate\n",
      "    storage = batch[0].storage()._new_shared(numel)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/storage.py\", line 118, in _new_shared\n",
      "    return cls._new_using_filename(size)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-129-6a37cb3567b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mxprime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxprime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "for epoch in range(6):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        \n",
    "        x,y=data\n",
    "        \n",
    "        scheduler.step()\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        xprime = net(x)\n",
    "        loss = criterion(xprime, x)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type autoencoder. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(net,'mnist025loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "net=torch.load('mnist025loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store encoded values\n",
    "X=[]\n",
    "Y=[]\n",
    "net.fc4.register_forward_hook(saveencoded)\n",
    "\n",
    "for x,y in trainloader:\n",
    "    Y+=y.numpy().tolist()\n",
    "    decoded=net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(30.7117, grad_fn=<SumBackward0>)\n",
      "[2]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-64:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(testloader)\n",
    "dataiter.next()\n",
    "# dataiter.next()\n",
    "image, label = dataiter.next()\n",
    "print(criterion(image,net(image)))\n",
    "print(label.numpy().tolist())\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(image))\n",
    "plt.show()\n",
    "imshow(torchvision.utils.make_grid(net(image).detach()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 0 into shape (50002,1440)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-2a35f26ea33f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50002\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 0 into shape (50002,1440)"
     ]
    }
   ],
   "source": [
    "# X=np.array(X)\n",
    "# X.reshape(50002,3*32*15)\n",
    "# Y=np.array(Y).reshape(50000,1)\n",
    "# print(X.shape)\n",
    "# print(Y.shape)\n",
    "# print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=9, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#X= encoded cifar pics\n",
    "#y=labels\n",
    "\n",
    "\n",
    "\n",
    "neigh = KNeighborsClassifier(n_neighbors=9)\n",
    "neigh.fit(X, Y)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=[]\n",
    "Y=[]\n",
    "\n",
    "for x,y in testloader:\n",
    "    Y+=y.numpy().tolist()\n",
    "    decoded=net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X=np.array(X)\n",
    "# X=X.reshape(10000,3*32*15)\n",
    "# Y=np.array(Y).reshape(10000,1)\n",
    "# print(X.shape)\n",
    "# print(Y.shape)\n",
    "# #print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_correct=0\n",
    "total_num=0\n",
    "X=np.array(X)\n",
    "Y=np.array(Y)\n",
    "for i in range(10000):\n",
    "    x=X[i]\n",
    "    y=Y[i]\n",
    "    \n",
    "    y_pred=neigh.predict(x.reshape(1,-1))\n",
    "    if y_pred==y:\n",
    "        num_correct+=1\n",
    "    if i%2000==0:\n",
    "        print(num_correct,i)\n",
    "   \n",
    "    total_num+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"accuracy: \"+str(float(num_correct)/total_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
